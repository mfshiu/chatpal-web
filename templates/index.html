<!DOCTYPE html>

<html
  lang="en"
  class="light-style layout-navbar-fixed layout-menu-fixed"
  dir="ltr"
  data-theme="theme-default"
  data-assets-path="../static/assets/"
  data-template="vertical-menu-template"
>
  <head>
    {% include 'layout/head.html' %}

    <style>
    </style>
  </head>

  <body>
    <!-- Layout wrapper -->
    <div class="layout-wrapper layout-content-navbar">
      <div class="layout-container">
        {% include 'layout/menu.html' %}

        <!-- Layout container -->
        <div class="layout-page">

          {% include 'layout/navbar.html' %}

          <div class="content-wrapper">
            <!-- Content -->
            <div class="container-xxl flex-grow-1 container-p-y">
              <button id="startButton" class="btn btn-primary">Start</button>
              <button id="stopButton" class="btn btn-danger">Stop</button>
            </div>
            <!-- / Content -->

            {% include 'layout/footer.html' %}

            <div class="content-backdrop fade"></div>
          </div>
        </div>
        <!-- / Layout page -->
      </div>

      <!-- Overlay -->
      <div class="layout-overlay layout-menu-toggle"></div>

      <!-- Drag Target Area To SlideIn Menu On Small Screens -->
      <div class="drag-target"></div>
    </div>
    <!-- / Layout wrapper -->

    {% include 'layout/bodytail.html' %}

    <script>
      $(document).ready(function () {
        
      });
    </script>

    <script>
      let is_paused = false;
      let mediaRecorder;
      let audioChunks = [];

      document.getElementById('startButton').addEventListener('click', async function() {
        console.log('Start recording.');
        is_paused = false;

        let audioContext = new (window.AudioContext || window.webkitAudioContext)();
        await audioContext.audioWorklet.addModule("{{ url_for('static', filename='js/audio-processor.js') }}");
    
        let microphoneStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        let microphone = audioContext.createMediaStreamSource(microphoneStream);
        let audioProcessorNode = new AudioWorkletNode(audioContext, 'audio-processor');
    
        audioProcessorNode.port.onmessage = (event) => {
          if (is_paused) {
            return
          }

          if (event.data.speaking) {
            console.log('Recording...');
            navigator.mediaDevices.getUserMedia({ audio: true })
              .then(stream => {
                mediaRecorder = new MediaRecorder(stream);
                mediaRecorder.ondataavailable = event => audioChunks.push(event.data);
                mediaRecorder.start();
              });
          }
          else {
            console.log('stop');
            mediaRecorder.stop();
            mediaRecorder.onstop = () => {
              const audioBlob = new Blob(audioChunks, { 'type' : 'audio/wav; codecs=opus' });
              audioChunks = [];

              var formData = new FormData();
              formData.append("audio_data", audioBlob);
              fetch("/upload_voice", { method: "POST", body: formData });
            }
          }
        };
    
        microphone.connect(audioProcessorNode).connect(audioContext.destination);
      });

      document.getElementById('stopButton').addEventListener('click', async function() {
        console.log('Stop recording.');
        is_paused = true;
        audioChunks = [];
      });
    </script>
  </body>
</html>
