<!DOCTYPE html>

<html
  lang="en"
  class="light-style layout-navbar-fixed layout-menu-fixed"
  dir="ltr"
  data-theme="theme-default"
  data-assets-path="../static/assets/"
  data-template="vertical-menu-template"
>
  <head>
    {% include 'layout/head.html' %}

    <style>
      .book-data-row {
        cursor: pointer;
      }

      .row-select {
        background-color: gainsboro;
      }
    </style>
  </head>

  <body>
    <!-- Layout wrapper -->
    <div class="layout-wrapper layout-content-navbar">
      <div class="layout-container">
        {% include 'layout/menu.html' %}

        <!-- Layout container -->
        <div class="layout-page">

          {% include 'layout/navbar.html' %}

          <div class="content-wrapper">
            <!-- Content -->
            <button id="startButton">Start</button>
            <!-- / Content -->

            {% include 'layout/footer.html' %}

            <div class="content-backdrop fade"></div>
          </div>
        </div>
        <!-- / Layout page -->
      </div>

      <!-- Overlay -->
      <div class="layout-overlay layout-menu-toggle"></div>

      <!-- Drag Target Area To SlideIn Menu On Small Screens -->
      <div class="drag-target"></div>
    </div>
    <!-- / Layout wrapper -->

    {% include 'layout/bodytail.html' %}

    <script>
      $(document).ready(function () {
        
      });
    </script>

    <script>
      class AudioProcessor extends AudioWorkletProcessor {
        process(inputs, outputs, parameters) {
            // Your audio processing logic goes here
            return true;
        }
      }      
      registerProcessor('audio-processor', AudioProcessor);
    
      document.getElementById('startButton').addEventListener('click', function() {
        const voiceActivityThreshold = 50; // This value can be adjusted based on testing
        let audioContext = new (window.AudioContext || window.webkitAudioContext)();
        let analyser = audioContext.createAnalyser();
        let microphone;
        let javascriptNode;
        
        navigator.mediaDevices.getUserMedia({ audio: true, video: false })
          .then(function(stream) {
            microphone = audioContext.createMediaStreamSource(stream);
            javascriptNode = audioContext.createScriptProcessor(2048, 1, 1);
    
            analyser.smoothingTimeConstant = 0.8;
            analyser.fftSize = 1024;
    
            microphone.connect(analyser);
            analyser.connect(javascriptNode);
            javascriptNode.connect(audioContext.destination);
    
            javascriptNode.onaudioprocess = function() {
                let array = new Uint8Array(analyser.frequencyBinCount);
                analyser.getByteFrequencyData(array);
                let values = 0;
    
                let length = array.length;
                for (let i = 0; i < length; i++) {
                    values += (array[i]);
                }
    
                let average = values / length;
    
                // Check if average is over a predefined threshold
                if (average > voiceActivityThreshold) {
                  console.log("Speaking");
                } else {
                  console.log("Silence");
                }
              }
          })
          .catch(function(err) {
            console.log(err);
          });
      });
      
      // Placeholder function for VAD - you would replace this with a real implementation
      function isUserSpeaking() {
          // Implement VAD logic here
          return true; // This should be the result of the VAD check
      }

      let recording = false;
      let silenceTimer;
      const maxDuration = 10000; // 10 seconds
      let mediaRecorder;
      let audioChunks = [];

      navigator.mediaDevices.getUserMedia({ audio: true })
        .then(stream => {
          mediaRecorder = new MediaRecorder(stream);
          mediaRecorder.ondataavailable = event => audioChunks.push(event.data);

          setInterval(() => {
              if (isUserSpeaking()) {
                  if (!recording) {
                      audioChunks = [];
                      mediaRecorder.start();
                      recording = true;

                      setTimeout(() => {
                          if (recording) {
                              mediaRecorder.stop();
                              recording = false;
                          }
                      }, maxDuration);
                  }

                  clearTimeout(silenceTimer);
                  silenceTimer = setTimeout(() => {
                      if (recording) {
                          mediaRecorder.stop();
                          recording = false;
                      }
                  }, 1000); // Stop if silence for more than 1 second
              }
          }, 100); // Check every 100ms

          mediaRecorder.onstop = () => {
            var audioBlob = new Blob(audioChunks);
            var formData = new FormData();
            formData.append("audio_data", audioBlob);
            fetch("/upload_voice", { method: "POST", body: formData });
          };
        });
    </script>
  </body>
</html>
